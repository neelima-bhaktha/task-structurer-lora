Activation functions introduce non-linearity into neural networks. Without them, deep networks reduce to linear models and lose expressive power.